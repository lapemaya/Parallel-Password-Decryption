\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{booktabs}
\usepackage{multirow}

% Include other packages here, before hyperref.

% If you comment hyperref and then uncomment it, you should delete
% egpaper.aux before re-running latex.
\usepackage[breaklinks=true,bookmarks=false]{hyperref}

\title{Parallel Password Decryption using OpenMP:\\ Performance Analysis and Optimization}

\author{First Author\\
University of Florence\\
{\tt\small firstauthor@unifi.it}
}

\begin{document}

\maketitle

\begin{abstract}
This report presents a comprehensive analysis of parallel password decryption using OpenMP for brute-force attacks on DES-encrypted passwords. The study implements and compares three algorithmic variants: a sequential baseline, a parallel implementation with implicit barriers, and an optimized parallel version with nowait clauses. Performance benchmarks across 1-20 threads reveal that the parallel NOWAIT implementation achieves a maximum speedup of 10.92$\times$ with 20 threads, processing approximately 3.9 million passwords per second. The analysis examines execution time, speedup, efficiency, scalability, and throughput characteristics, demonstrating the effectiveness of OpenMP parallelization for computationally intensive cryptographic operations while highlighting diminishing returns beyond 8 threads due to overhead and resource contention.
\end{abstract}

\section{Future Distribution Permission}
The author(s) of this report give permission for this document to be distributed to Unifi-affiliated students taking future courses.

\section{Introduction}

Password security remains a critical concern in modern computing systems. Understanding the computational effort required to crack encrypted passwords through brute-force methods provides valuable insights into password strength and the effectiveness of parallelization strategies for cryptographic applications. This project implements a parallel brute-force password cracking system targeting 8-character date-based passwords (format: ddmmyyyy) encrypted using the DES algorithm.

The primary objective is to evaluate the performance characteristics of OpenMP-based parallelization compared to sequential execution, analyzing how different thread counts and optimization strategies affect execution time, speedup, efficiency, and overall throughput. The implementation tests passwords in the date range from 01011970 to 31122025, representing a search space of approximately 844,000 combinations per iteration.

\subsection{Problem Statement}

Given a DES-encrypted password hash with salt "AB", the goal is to systematically test all possible 8-digit date combinations (ddmmyyyy format) to find the original plaintext password. The computational challenge lies in the cryptographic overhead of the crypt() function, which must be called for each candidate password. This makes the problem an ideal candidate for parallelization, as each password test is independent and computationally expensive.

\subsection{Contributions}

This project makes the following contributions:

\begin{itemize}
\item Three algorithmic implementations: Sequential baseline, parallel with barriers, and parallel with nowait optimization
\item Comprehensive performance analysis: Benchmarking across 1, 2, 4, 8, 16, and 20 threads
\item Multiple performance metrics: Speedup, efficiency, scalability, and throughput analysis
\item Optimization techniques: Thread-local crypt\_data structures, early termination with atomic flags, and barrier elimination
\end{itemize}

\section{Methodology}

\subsection{Algorithm Design}

The brute-force password cracking algorithm consists of three nested loops iterating over days (0-31), months (0-12), and years (0-2025). For each iteration combination, the algorithm constructs an 8-character date string manually, encrypts the candidate password using crypt\_r() with DES and salt "AB", compares the resulting hash with the target hash, and terminates early upon finding a match using atomic flag synchronization. The search space per iteration is: $32 \times 13 \times 2026 = 842,816$ password candidates.

\subsection{Implementation Variants}

\textbf{Sequential Implementation:} Single-threaded baseline using standard crypt() function with simple early termination using boolean flag and no parallelization overhead.

\textbf{Parallel Implementation:} OpenMP parallel for with collapse(3) directive, thread-local crypt\_data structures using crypt\_r(), atomic boolean flag for early termination, implicit barrier at end of parallel region, and cancellation points for improved early exit.

\textbf{Parallel NOWAIT Implementation:} Identical to parallel version but with nowait clause to eliminate implicit barrier synchronization and reduce thread synchronization overhead.



% Detailed list of implemented optimizations and rationale
\subsection{Detailed implemented optimizations}
To make the performance improvements and measurements repeatable and easy to reason about, the following concrete optimizations were implemented in the codebase. For each item we report the change made and the expected/runtime effect.

\begin{itemize}
  \item \textbf{Manual date string construction (char buffer)}: constructing the 8-character candidate password by arithmetic on integers (e.g. '0' + digit) instead of using higher-level string formatting (streams or sprintf) reduces per-candidate overhead and heap activity. Expected effect: lower CPU time per candidate and less allocator-related jitter.

  \item \textbf{Per-thread crypt\_data with crypt\_r()}: each thread uses a separate \texttt{crypt\_data} struct and the reentrant \texttt{crypt\_r()} function instead of the non-reentrant \texttt{crypt()}. This removes shared-state contention and avoids sequentialization of the cryptographic routine. Expected effect: improved parallel scalability and correct behavior under multithreading.

  \item \textbf{Quick-reject hash comparison}: before performing a full \texttt{strcmp()} on the produced DES hash, the implementation checks two representative bytes (positions 3 and 4). Most candidates fail this cheap check, so this reduces expensive string comparisons. Expected effect: fewer full comparisons, measurable CPU savings.

  \item \textbf{Atomic early-termination flag with memory ordering}: an \texttt{std::atomic<bool>} flag is used for early termination. The code uses relaxed loads for frequent checks and a release store when setting the flag. This balances correctness with low-overhead polling. Expected effect: fast early exit with minimal synchronization cost.

  \item \textbf{OpenMP cancellation points for prompt exit}: cancellation points and \texttt{\#pragma omp cancel for} are used so threads can stop iterating promptly when a match is found. Note: cancellation implies implicit synchronization semantics; in particular, cancellation cannot be combined with the \texttt{nowait} clause on the same construct. Expected effect: faster termination when the password is found, at the cost of some synchronization semantics that must be accounted for in the NOWAIT variant.

  \item \textbf{Static work distribution (schedule(static)) and collapse(3)}: collapsing the three nested loops and using static scheduling gives deterministic, low-overhead partitioning of the search space. Expected effect: reduced runtime scheduling overhead and good cache locality for contiguous iteration chunks.

  \item \textbf{Reduction for password counting}: using OpenMP \texttt{reduction(+:total\_passwords\_tested)} avoids atomic increments on the hot path while still collecting global statistics. Expected effect: lower contention on the global counter and accurate aggregated metrics.

  \item \textbf{Minimal per-iteration allocations}: avoiding dynamic allocations inside the hot loop (e.g. no temporary std::string creation per candidate) prevents allocator contention and reduces cache pollution. Expected effect: lower latency per candidate and more consistent timings.
\end{itemize}

\noindent Each optimization above was chosen to address a specific bottleneck (CPU per-candidate cost, synchronization, memory/cache contention, or measurement noise) and together they produce the observed throughput and scaling characteristics .

\subsection{Experimental Setup}

\textbf{Hardware Configuration:} Intel Core i9-13900H (13th Gen) with 14 cores (20 threads with Hyper-Threading), Linux-based system (Ubuntu), OpenMP 4.0+ support.

\textbf{Software Configuration:} Compiler g++ with -fopenmp flag, OpenMP Cancellation enabled via OMP\_CANCELLATION=true, 500 iterations per test, thread counts tested: 1, 2, 4, 8, 16, 20.

\textbf{Metrics Collected:} Total execution time, average time per iteration, total passwords tested, passwords per second (throughput), speedup, efficiency, and scalability.

\section{Results and Analysis}

\subsection{Execution Time Analysis}

The execution time results demonstrate clear benefits of parallelization. Table \ref{tab:execution_time} shows the execution times for all three implementations across different thread counts.

\begin{table}[h]
\centering
\small
\begin{tabular}{cccc}
\toprule
\textbf{Threads} & \textbf{Seq (s)} & \textbf{Par (s)} & \textbf{NOWAIT (s)} \\
\midrule
1  & 598.40 & 578.60 & 588.36 \\
2  & ---    & 289.15 & 278.16 \\
4  & ---    & 158.26 & 161.08 \\
8  & ---    & 99.70  & 98.75  \\
16 & ---    & 69.22  & 65.90  \\
20 & ---    & 55.65  & 54.79  \\
\bottomrule
\end{tabular}
\caption{Execution times for sequential and parallel implementations}
\label{tab:execution_time}
\end{table}

\begin{figure}[h]
\centering
\includegraphics[width=\linewidth]{benchmark_results/benchmark_20251105_221836_execution_time.png}
\caption{Execution time comparison across different thread counts. The sequential baseline is shown as a horizontal dashed line, while parallel and parallel NOWAIT implementations show decreasing execution times as thread count increases.}
\label{fig:execution_time}
\end{figure}

Key observations include: the parallel version with 1 thread outperforms the sequential baseline by 3.3 percent, likely due to compiler optimizations enabled by OpenMP pragmas. Execution time decreases consistently as thread count increases from 1 to 20. The NOWAIT variant shows minimal improvement (1-5 percent) over the standard parallel implementation, with the largest gains at higher thread counts. Near-linear scaling is observed up to 4 threads, after which diminishing returns become apparent.

\subsection{Speedup Analysis}

Speedup is calculated as: $\text{Speedup} = T_{\text{sequential}} / T_{\text{parallel}}$. Table \ref{tab:speedup} presents the speedup results.

\begin{table}[h]
\centering
\small
\begin{tabular}{cccc}
\toprule
\textbf{Threads} & \textbf{Parallel} & \textbf{NOWAIT} & \textbf{Ideal} \\
\midrule
1  & 1.03$\times$ & 1.01$\times$ & 1.00$\times$ \\
2  & 2.06$\times$ & 2.15$\times$ & 2.00$\times$ \\
4  & 3.78$\times$ & 3.71$\times$ & 4.00$\times$ \\
8  & 6.00$\times$ & 6.05$\times$ & 8.00$\times$ \\
16 & 8.64$\times$ & 9.08$\times$ & 16.00$\times$ \\
20 & 10.75$\times$ & 10.92$\times$ & 20.00$\times$ \\
\bottomrule
\end{tabular}
\caption{Speedup comparison across implementations}
\label{tab:speedup}
\end{table}

\begin{figure}[h]
\centering
\includegraphics[width=\linewidth]{benchmark_results/benchmark_20251105_221836_speedup.png}
\caption{Speedup comparison showing parallel and parallel NOWAIT implementations against ideal linear speedup. The growing gap between achieved and ideal speedup illustrates the diminishing returns from additional threads.}
\label{fig:speedup}
\end{figure}

Analysis reveals super-linear speedup at 2 threads where the NOWAIT variant achieves 2.15$\times$ speedup, strong scaling up to 4 threads with 94-95 percent efficiency maintained, moderate scaling from 4-8 threads with efficiency dropping to approximately 75 percent, and diminishing returns beyond 8 threads. Maximum speedup of 10.92$\times$ is achieved with 20 threads using the NOWAIT version, representing 54 percent efficiency.

\subsection{Efficiency Analysis}

Parallel efficiency is calculated as: $\text{Efficiency} = (\text{Speedup} / \text{Threads}) \times 100\%$. Table \ref{tab:efficiency} shows efficiency results.

\begin{table}[h]
\centering
\small
\begin{tabular}{cccc}
\toprule
\textbf{Threads} & \textbf{Par Eff} & \textbf{NW Eff} & \textbf{Quality} \\
\midrule
1  & 103.0\% & 101.0\% & Excellent \\
2  & 103.0\% & 107.0\% & Excellent \\
4  & 94.0\%  & 92.0\%  & Very Good \\
8  & 75.0\%  & 75.0\%  & Good \\
16 & 54.0\%  & 56.0\%  & Moderate \\
20 & 53.0\%  & 54.0\%  & Moderate \\
\bottomrule
\end{tabular}
\caption{Parallel efficiency analysis}
\label{tab:efficiency}
\end{table}

\begin{figure}[h]
\centering
\includegraphics[width=\linewidth]{benchmark_results/benchmark_20251105_221836_efficiency.png}
\caption{Parallel efficiency showing the decline from near-optimal efficiency at 2 threads to moderate efficiency at 20 threads. The 100\% efficiency baseline emphasizes the performance degradation at higher thread counts.}
\label{fig:efficiency}
\end{figure}

Key findings show that the optimal thread count is 2-4 threads providing the best efficiency (92-107 percent). A significant efficiency cliff occurs between 4 and 8 threads (from 94 percent to 75 percent). Beyond 16 threads, efficiency stabilizes around 54 percent, and the NOWAIT variant consistently maintains 1-2 percent higher efficiency at higher thread counts.

\subsection{Throughput Analysis}

Throughput measures the computational work accomplished per unit time. Table \ref{tab:throughput} presents throughput results in passwords per second.

\begin{table}[h]
\centering
\small
\begin{tabular}{cccc}
\toprule
\textbf{Threads} & \textbf{Sequential} & \textbf{Parallel} & \textbf{NOWAIT} \\
\midrule
1  & 704,220 & 375,584   & 375,476   \\
2  & ---     & 747,562   & 747,979   \\
4  & ---     & 1,393,737 & 1,391,099 \\
8  & ---     & 2,185,314 & 2,190,975 \\
16 & ---     & 3,350,562 & 3,360,133 \\
20 & ---     & 3,900,869 & 3,879,653 \\
\bottomrule
\end{tabular}
\caption{Throughput in passwords per second}
\label{tab:throughput}
\end{table}

\begin{figure}[h]
\centering
\includegraphics[width=\linewidth]{benchmark_results/benchmark_20251105_221836_throughput.png}
\caption{Throughput analysis demonstrating nearly linear scaling up to 8 threads, followed by diminishing gains. The sequential baseline is shown for reference, with parallel implementations achieving up to 5.5$\times$ higher throughput.}
\label{fig:throughput}
\end{figure}

Notable observations include nearly linear throughput scaling that doubles from 2 to 4 threads and again from 4 to 8 threads. Peak throughput of 3.9 million passwords per second is achieved with 20 threads. However, throughput increase from 16 to 20 threads is only 16 percent, adding 550K passwords per second for 4 additional threads, demonstrating diminishing returns.

\subsection{Scalability Metrics}

Scalability measures how well the parallel implementation maintains efficiency as threads increase. Using 2 threads as baseline, the scalability results are shown in Table \ref{tab:scalability}.

\begin{table}[h]
\centering
\small
\begin{tabular}{ccc}
\toprule
\textbf{Threads} & \textbf{Parallel} & \textbf{NOWAIT} \\
\midrule
2  & 1.00 & 1.00 \\
4  & 0.92 & 0.86 \\
8  & 0.73 & 0.70 \\
16 & 0.52 & 0.53 \\
20 & 0.52 & 0.51 \\
\bottomrule
\end{tabular}
\caption{Scalability relative to 2-thread baseline}
\label{tab:scalability}
\end{table}

\begin{figure}[h]
\centering
\includegraphics[width=\linewidth]{benchmark_results/benchmark_20251105_221836_scalability.png}
\caption{Scalability analysis relative to 2-thread baseline performance. The declining trend indicates increasing overhead and contention as thread count grows, with significant degradation beyond 8 threads.}
\label{fig:scalability}
\end{figure}

The scalability curve shows that the implementation maintains good scalability up to 4 threads but experiences significant degradation beyond 8 threads, indicating architectural and algorithmic bottlenecks.

\section{Discussion}

\subsection{Performance Interpretation}

The experimental results reveal several important characteristics of parallel password cracking. The optimal configuration appears to be 4-8 threads, offering 3.7-6$\times$ speedup with 75-94 percent efficiency. This range balances computational throughput with resource utilization overhead.

The nowait optimization provides minimal benefit (1-5 percent improvement), suggesting that barrier synchronization is not the primary bottleneck. The largest gains appear at 16-20 threads, where thread coordination overhead becomes more significant.

The speedup curve closely follows Amdahl's Law predictions, where a small sequential portion (initialization, random number generation, final result collection) limits maximum speedup. Estimating the sequential fraction at approximately 8-10 percent explains the observed speedup plateau.

\subsection{Bottleneck Analysis}

Several factors limit scalability beyond 8 threads. Memory bandwidth becomes saturated as the crypt\_r() function requires significant memory operations with many concurrent threads. Cache effects manifest as thread-local crypt\_data structures cause cache line contention, especially with more than 8 threads competing for L3 cache. Early termination overhead accumulates as atomic flag checking on every iteration introduces synchronization costs. Load imbalance occurs because static scheduling with collapse(3) may not perfectly balance work when early termination occurs, leaving some threads idle. Finally, OpenMP runtime overhead from thread creation, scheduling, and management costs become proportionally larger with more threads.

\subsection{Real-World Implications}

For practical password cracking applications, 4-8 threads are optimal for single-node systems, providing best efficiency without excessive overhead. Beyond 8 threads, additional parallelization is only beneficial if absolute time reduction is critical and efficiency is secondary. For distributed systems, further parallelization would benefit from multi-node implementations using MPI rather than additional threads on a single node.

\section{Conclusions}

This study successfully implemented and evaluated parallel password decryption using OpenMP, demonstrating significant performance improvements over sequential execution. Maximum speedup of 10.92$\times$ was achieved with 20 threads using the NOWAIT optimization. The optimal thread count of 4-8 threads provides the best balance of speedup (3.7-6$\times$) and efficiency (75-94 percent). The nowait benefit is marginal (1-5 percent) improvement, most significant at high thread counts. Scalability limits appear beyond 8 threads due to memory bandwidth, cache contention, and synchronization overhead.

The implementation successfully leverages OpenMP's parallelization capabilities while employing critical optimizations such as thread-local state, manual string construction, and atomic synchronization. The results validate the effectiveness of data-parallel approaches for cryptographic brute-force applications while highlighting the practical limits of shared-memory parallelism.

\subsection{Future Work}

Potential extensions to this research include investigating dynamic scheduling to address load imbalance, exploring SIMD optimization and vectorization of comparison operations, evaluating GPU implementations using CUDA or OpenCL for massively parallel execution, implementing MPI versions for cluster-based password cracking, reducing atomic flag checking frequency through predictive termination, and comparing with rainbow table approaches or dictionary attacks.

{\small
\bibliographystyle{ieee}
\begin{thebibliography}{9}

\bibitem{openmp}
OpenMP Architecture Review Board.
\newblock OpenMP Application Programming Interface, Version 4.5.
\newblock November 2015.

\bibitem{chandra}
R. Chandra, L. Dagum, D. Kohr, D. Maydan, J. McDonald, and R. Menon.
\newblock Parallel Programming in OpenMP.
\newblock Morgan Kaufmann, 2001.

\bibitem{amdahl}
G. M. Amdahl.
\newblock Validity of the single processor approach to achieving large scale computing capabilities.
\newblock AFIPS Conference Proceedings, 1967.

\bibitem{gustafson}
J. L. Gustafson.
\newblock Reevaluating Amdahl's Law.
\newblock Communications of the ACM, 31(5):532-533, 1988.

\bibitem{des}
NIST.
\newblock Data Encryption Standard (DES).
\newblock FIPS PUB 46-3, Federal Information Processing Standards Publication, 1999.

\end{thebibliography}
}

\section{Appendix}

This project was developed independently as part of the Parallel Computing course requirements. All implementations, experiments, and analysis were conducted solely by the author(s).



\end{document}

